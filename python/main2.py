import sys
import os
import json
import logging
from pathlib import Path
from typing import List, Dict, Tuple
from datetime import datetime  
from dataclasses import dataclass
import argparse

# LLM ë¼ì´ë¸ŒëŸ¬ë¦¬ import
# pip install google-generativeai
# export GOOGLE_API_KEY="ì—¬ê¸°ì—_ë³µì‚¬í•œ_API_í‚¤ë¥¼_ë¶™ì—¬ë„£ìœ¼ì„¸ìš”"
import google.generativeai as genai

# --- ë°ì´í„° í´ë˜ìŠ¤ ë° íŒŒì¼ ë¦¬ë” ---

@dataclass
class LogReaderConfig:
    """ë¡œê·¸ ë¦¬ë”ì˜ ì„¤ì •ì„ ë‹´ëŠ” ë°ì´í„° í´ë˜ìŠ¤"""
    file_path: Path
    encoding: str = 'auto'
    candidate_encodings: List[str] = None
    
    def __post_init__(self):
        """ê°ì²´ ìƒì„± í›„ ì´ˆê¸°í™” ë©”ì„œë“œ"""
        if self.candidate_encodings is None:
            self.candidate_encodings = ['utf-8', 'utf-8-sig', 'cp949', 'euc-kr', 'latin1']

class MissionLogReader:
    """ë¡œê·¸ íŒŒì¼ì„ ì½ê³  ê¸°ë³¸ì ì¸ ìœ íš¨ì„± ê²€ì‚¬ë¥¼ ìˆ˜í–‰í•˜ëŠ” í´ë˜ìŠ¤"""
    def __init__(self, config: LogReaderConfig):
        self.config = config
        self._setup_logging()
        self.detected_encoding = None

    def _setup_logging(self) -> None:
        """ë¡œê¹… ê¸°ë³¸ ì„¤ì •"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            datefmt='%Y-%m-%d %H:%M:%S'
        )
        self.logger = logging.getLogger(self.__class__.__name__)

    def _validate_file(self) -> None:
        """íŒŒì¼ ì¡´ì¬ ì—¬ë¶€, íŒŒì¼/ë””ë ‰í† ë¦¬ ì—¬ë¶€, ì½ê¸° ê¶Œí•œì„ ê²€ì‚¬í•©ë‹ˆë‹¤."""
        if not self.config.file_path.exists():
            raise FileNotFoundError(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.config.file_path}")
        if not self.config.file_path.is_file():
            raise ValueError(f"ê²½ë¡œê°€ íŒŒì¼ì´ ì•„ë‹™ë‹ˆë‹¤: {self.config.file_path}")

    def _detect_encoding(self) -> str:
        
        for encoding in self.config.candidate_encodings:
            try:
                with open(self.config.file_path, 'r', encoding=encoding) as f:
                    f.read(1024) # í…ŒìŠ¤íŠ¸ë¡œ ì¼ë¶€ë§Œ ì½ê¸°
                self.logger.info(f"íŒŒì¼ ì¸ì½”ë”© ê°ì§€ ì„±ê³µ: {encoding}")
                self.detected_encoding = encoding
                return encoding
            except UnicodeDecodeError:
                continue
        raise UnicodeDecodeError(f"ì§€ì›í•˜ëŠ” ì¸ì½”ë”©ìœ¼ë¡œ íŒŒì¼ì„ ë””ì½”ë”©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.config.file_path}")

    def read_entire_file(self) -> List[str]:
        """íŒŒì¼ ì „ì²´ ë‚´ìš©ì„ ì½ì–´ ì¤„ ë‹¨ìœ„ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""
        try:
            self._validate_file()
            encoding = self._detect_encoding()
            self._print_header()

            with open(self.config.file_path, 'r', encoding=encoding) as f:
                lines = f.readlines()

            return lines

        except (FileNotFoundError, PermissionError, ValueError, UnicodeDecodeError) as e:
            self.logger.error(e)
            print(f"âŒ ì—ëŸ¬ ë°œìƒ: {e}", file=sys.stderr)
            return None # ì‹¤íŒ¨ ì‹œ None ë°˜í™˜
        except Exception as e:
            self.logger.exception(f"ì˜ˆìƒì¹˜ ëª»í•œ ì—ëŸ¬ ë°œìƒ: {e}")
            print(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì—ëŸ¬: {e}", file=sys.stderr)
            return None
    
    def _print_header(self) -> None:
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        # í˜„ì¬ ì‹œê°„ì„ ë¬¸ìì—´ë¡œ ë³€í™˜
        
        header = f"\n{'='*60}\nğŸ“„ Log File: {self.config.file_path.name}\n"
        header += f"ğŸ“… Read at: {timestamp}\n"
        header += f"ğŸ“ Program Name: main.py\n"
        header += f"{'='*60}\n\n"
        print(header)

# --- ë¡œê·¸ ë°ì´í„° ì²˜ë¦¬ í´ë˜ìŠ¤ ---

class LogProcessor:
    """ë¡œê·¸ ë°ì´í„°ë¥¼ íŒŒì‹±, ì •ë ¬, ë³€í™˜ ë° ì €ì¥í•˜ëŠ” í´ë˜ìŠ¤"""
    def __init__(self):
        self.logger = logging.getLogger(self.__class__.__name__)

    def parse_logs(self, log_lines: List[str]) -> List[List[str]]:
        parsed_data = []
        for i, line in enumerate(log_lines):
            line = line.strip()
            if not line:
                continue # ë¹ˆ ì¤„ì€ ê±´ë„ˆë›°ê¸°
            
            parts = line.split(',', 2) 
            if len(parts) == 3:
                timestamp, message = parts[0].strip(), parts[2].strip()
                parsed_data.append([timestamp, message])
            else:
                self.logger.warning(f"{i+1}ë²ˆì§¸ ì¤„ íŒŒì‹± ì‹¤íŒ¨ (í¬ë§· ì˜¤ë¥˜): {line}")
        print("âœ… ë¡œê·¸ ë‚´ìš© íŒŒì‹± ì™„ë£Œ.")
        return parsed_data

    def sort_logs_desc(self, logs: List[List[str]]) -> List[List[str]]:
        sorted_logs = sorted(logs, key=lambda item: item[0], reverse=True)
        print("âœ… ì‹œê°„ ì—­ìˆœìœ¼ë¡œ ì •ë ¬ ì™„ë£Œ.")
        return sorted_logs

    def convert_to_dict(self, logs: List[List[str]]) -> Dict[str, str]:
        """ì •ë ¬ëœ ë¡œê·¸ ë¦¬ìŠ¤íŠ¸ë¥¼ {ì‹œê°„: ë©”ì‹œì§€} í˜•íƒœì˜ ì‚¬ì „ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
        log_dict = {timestamp: message for timestamp, message in logs}
        print("âœ… ì‚¬ì „(Dict) ê°ì²´ë¡œ ë³€í™˜ ì™„ë£Œ.")
        return log_dict

    def save_as_json(self, data: Dict[str, str], output_path: Path) -> None:
        """ì‚¬ì „ ë°ì´í„°ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
        try:
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=0)
            print(f"âœ… JSON íŒŒì¼ ì €ì¥ ì™„ë£Œ: {output_path}")
        except Exception as e:
            self.logger.error(f"JSON íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")
            print(f"âŒ JSON íŒŒì¼ ì €ì¥ ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}", file=sys.stderr)

class LLMReportGenerator:
    
    def __init__(self):
        self.logger = logging.getLogger(self.__class__.__name__)
        self.model = None
        try:
            # í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ë¥¼ ì•ˆì „í•˜ê²Œ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.
            key = os.getenv("GOOGLE_API_KEY")
            if not key:
                raise ValueError("í™˜ê²½ ë³€ìˆ˜ì—ì„œ 'GOOGLE_API_KEY'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
            
            genai.configure(api_key=key)

            self.model = genai.GenerativeModel('gemini-1.5-flash')
            self.logger.info("Gemini ëª¨ë¸ì´ ì„±ê³µì ìœ¼ë¡œ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")

        except Exception as e:
            self.logger.error(f"Gemini ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            print(f"âŒ LLM ë¦¬í¬íŠ¸ ìƒì„±ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}", file=sys.stderr)

    def _create_prompt(self, logs: List[List[str]]) -> str:

        # ë¡œê·¸ ë°ì´í„°ë¥¼ LLMì´ ì´í•´í•˜ê¸° ì‰¬ìš´ ë¬¸ìì—´ í˜•íƒœë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
        log_str = "\n".join([f"{ts}, {msg}" for ts, msg in logs]) # ì‹œê°„ìˆœìœ¼ë¡œ ì œê³µ

        # LLMì—ê²Œ ì—­í• , ì‘ì—…, ë°ì´í„°, ì¶œë ¥ í˜•ì‹ì„ êµ¬ì²´ì ìœ¼ë¡œ ì§€ì‹œí•©ë‹ˆë‹¤.
        prompt = f"""
        ### ì—­í• : ë‹¹ì‹ ì€ ìµœê³ ì˜ ìš°ì£¼ì„  ì‹œìŠ¤í…œ ì‚¬ê³  ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ì„ë¬´ ì»´í“¨í„° ë¡œê·¸ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì „ë¬¸ì ì´ê³  ì²´ê³„ì ì¸ 'ì‚¬ê³  ì›ì¸ ë¶„ì„ ë³´ê³ ì„œ'ë¥¼ ì‘ì„±í•´ ì£¼ì‹­ì‹œì˜¤.

        ### ë¶„ì„í•  ë¡œê·¸ ë°ì´í„°:
        ```
        {log_str}
        ```

        ### ë³´ê³ ì„œì— ë°˜ë“œì‹œ í¬í•¨ë˜ì–´ì•¼ í•  í•­ëª©:
        1.  **ê°œìš”**: ë³´ê³ ì„œì˜ ëª©ì ì„ ê°„ëµíˆ ì„œìˆ í•©ë‹ˆë‹¤.
        2.  **ì‚¬ê³  íƒ€ì„ë¼ì¸ ë¶„ì„**: ë¡œê·¸ì— ë‚˜íƒ€ë‚œ ì£¼ìš” ê²½ê³ (WARNING), ì˜¤ë¥˜(ERROR), ê·¸ë¦¬ê³  ì¹˜ëª…ì (CRITICAL/FATAL) ì´ë²¤íŠ¸ë¥¼ ì‹œê°„ìˆœìœ¼ë¡œ ìš”ì•½í•˜ì—¬ ì¬êµ¬ì„±í•©ë‹ˆë‹¤.
        3.  **ì‚¬ê³  ì›ì¸ ì¶”ë¡ **: íƒ€ì„ë¼ì¸ì„ ë°”íƒ•ìœ¼ë¡œ ì´ë²¤íŠ¸ ê°„ì˜ ì¸ê³¼ ê´€ê³„ë¥¼ ë¶„ì„í•˜ì—¬, ì‚¬ê³ ì˜ ê°€ì¥ í•µì‹¬ì ì¸ ì›ì¸(Root Cause)ì„ ë…¼ë¦¬ì ìœ¼ë¡œ ì¶”ë¡ í•©ë‹ˆë‹¤.
        4.  **ê¶Œê³  ì‚¬í•­**: ì¶”ë¡ ëœ ì›ì¸ì„ ë°”íƒ•ìœ¼ë¡œ, í–¥í›„ ë™ì¼í•œ ì‚¬ê³ ì˜ ì¬ë°œì„ ë°©ì§€í•˜ê¸° ìœ„í•œ êµ¬ì²´ì ì´ê³  ì‹¤ì§ˆì ì¸ ëŒ€ì±…ì„ 3ê°€ì§€ ì œì‹œí•©ë‹ˆë‹¤.

        ### ì¶œë ¥ í˜•ì‹:
        - ë°˜ë“œì‹œ Markdownì„ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.
        - ì œëª©ì€ `ğŸš€ ì‚¬ê³  ì›ì¸ ë¶„ì„ ë³´ê³ ì„œ` ë¡œ ì‹œì‘í•´ ì£¼ì„¸ìš”.
        - í•œêµ­ì–´ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”.
        """
        return prompt

    def generate_analysis_report(self, logs: List[List[str]], output_path: Path) -> bool:

        if not self.model:
            print("âŒ ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•„ ë³´ê³ ì„œë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", file=sys.stderr)
            return False

        print("\nğŸ¤– LLMì„ ì‚¬ìš©í•˜ì—¬ ì‚¬ê³  ì›ì¸ ë¶„ì„ ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ì ì‹œ ê¸°ë‹¤ë ¤ ì£¼ì„¸ìš”...")
        
        try:
            prompt = self._create_prompt(logs)
            response = self.model.generate_content(prompt)
            
            # LLMì´ ìƒì„±í•œ í…ìŠ¤íŠ¸ë¥¼ íŒŒì¼ì— ì €ì¥í•©ë‹ˆë‹¤.
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(response.text)
            
            print(f"âœ… LLM ê¸°ë°˜ ë¶„ì„ ë³´ê³ ì„œ ì €ì¥ ì™„ë£Œ: {output_path}")
            return True
        except Exception as e:
            self.logger.error(f"LLM ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨: {e}")
            print(f"âŒ LLM ë³´ê³ ì„œ ìƒì„± ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}", file=sys.stderr)
            return False

# --- ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ ---

def main() -> int:
    """ìŠ¤í¬ë¦½íŠ¸ì˜ ë©”ì¸ ë¡œì§ì„ ì‹¤í–‰í•©ë‹ˆë‹¤."""
    
    # 1. ì„¤ì • ë° ê°ì²´ ìƒì„±
    log_file = Path("mission_computer_main.log")
    json_output_file = Path("mission_computer_main.json")
    report_file = Path("log_analysis.md")

    config = LogReaderConfig(file_path=log_file)
    reader = MissionLogReader(config)
    processor = LogProcessor()
    reporter = LLMReportGenerator()

    # 2. ë¡œê·¸ íŒŒì¼ ì½ê¸°
    log_lines = reader.read_entire_file()
    if log_lines is None:
        return 1
    print("\n--- [ ì›ë³¸ ë¡œê·¸ íŒŒì¼ ë‚´ìš© ] ---")
    for line in log_lines:
        print(line, end='')
    print(f"\n{'='*60}\nâœ… End of log file\n{'='*60}")

    # 3. ë¡œê·¸ íŒŒì‹±
    parsed_logs = processor.parse_logs(log_lines)
    if not parsed_logs:
        return 1
    print("\n--- [ íŒŒì‹±ëœ ë¦¬ìŠ¤íŠ¸ ê°ì²´ ] ---")
    for log in parsed_logs:
        print(f'{log}')
    print(f"{'='*60}\nâœ… End of parsed logs\n{'='*60}")

    # 4. ì‹œê°„ ì—­ìˆœ ì •ë ¬
    sorted_logs = processor.sort_logs_desc(parsed_logs)
    if not sorted_logs:
        return 1
    print("\n--- [ ì‹œê°„ ì—­ìˆœìœ¼ë¡œ ì •ë ¬ëœ ë¦¬ìŠ¤íŠ¸ ] ---")
    for log in sorted_logs:
        print(log)
    print(f"{'='*60}\nâœ… End of sorted logs\n{'='*60}")

    # 5. ì‚¬ì „ ê°ì²´ë¡œ ë³€í™˜
    log_dict = processor.convert_to_dict(sorted_logs)
    if not log_dict:
        return 1

    # 6. JSON íŒŒì¼ë¡œ ì €ì¥
    result = processor.save_as_json(log_dict, json_output_file)
    if result is False:
        return 1

    # 7. ì‚¬ê³  ì›ì¸ ë¶„ì„ ë³´ê³ ì„œ ì‘ì„±
    report_result = reporter.generate_analysis_report(parsed_logs, report_file)
    if report_result is False:
        return 1

    print("\nğŸ‰ ëª¨ë“  ì‘ì—…ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
    return 0


if __name__ == "__main__":
    sys.exit(main())
